[["caso-práctico-modelo-qsar-regresión-lineal-múltiple.html", "Sección 8 Caso Práctico Modelo QSAR: Regresión Lineal Múltiple", " Sección 8 Caso Práctico Modelo QSAR: Regresión Lineal Múltiple Este caso práctico se enfoca en la construcción de un modelo QSAR (Análisis Cuantitativo de Relación Estructura-Actividad) mediante regresión lineal múltiple (MLR). Los datos de partida se obtuvieron del artículo titulado “QSAR Study of (5-Nitroheteroaryl-1,3,4-Thiadiazole-2-yl) Piperazinyl Derivatives to Predict New Similar Compounds as Antileishmanial Agents”. En dicho artículo, se llevaron a cabo estudios QSAR que incluyeron análisis de componentes principales (PCA), regresión lineal múltiple (MLR), regresión no lineal (RNLM) y cálculos de redes neuronales artificiales (ANN) en una serie de 36 compuestos derivados de (5-Nitroheteroaryl-1,3,4-Thiadiazole-2-yl) Piperazinyl. El objetivo principal era identificar las características estructurales clave necesarias para diseñar nuevos candidatos potentes de esta clase para la actividad antileishmanial. En este caso práctico, nos proponemos comparar los resultados obtenidos en nuestro ejercicio con los del mencionado artículo, en especial con en el método de regresión lineal múltiple. La estructura de este caso práctico se dividirá en las siguientes secciones: recopilación de datos, descripción de descriptores moleculares, construcción del modelo, validación del modelo y comparación de resultados. En el artículo se realizaron múltiples regresiones lineales utilizando el software XLSTAT versión 2013 para predecir los efectos sobre la actividad antileishmania. Nosotros implementaremos el desarrollo del modelo utilizando Rstudio con tidymodels. # Cargar librerias library(tidymodels) # Modelado de datos ## ── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ── ## ✔ broom 1.0.5 ✔ recipes 1.0.8 ## ✔ dials 1.2.0 ✔ rsample 1.2.0 ## ✔ dplyr 1.1.3 ✔ tibble 3.2.1 ## ✔ ggplot2 3.4.3 ✔ tidyr 1.3.0 ## ✔ infer 1.0.5 ✔ tune 1.1.2 ## ✔ modeldata 1.2.0 ✔ workflows 1.1.3 ## ✔ parsnip 1.1.1 ✔ workflowsets 1.0.1 ## ✔ purrr 1.0.2 ✔ yardstick 1.2.0 ## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ── ## ✖ purrr::discard() masks scales::discard() ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ✖ recipes::step() masks stats::step() ## • Search for functions across packages at https://www.tidymodels.org/find/ library(readxl) # Importar datos desde archivos Excel library(yardstick) Datos Fuente de datos La información sobre la actividad antileishmanial experimental (\\(pIC_{50}\\) en μM) de 36 derivados de tiadiazol se ha recopilado de un estudio previo. Cabe destacar que los valores de \\(pIC_{50}\\) para las 30 moléculas que componen el conjunto de entrenamiento del modelo oscilan en un rango que va desde 3,155 y 5,046. Los detalles sobre las moléculas y sus respectivas actividades biológicas calculadas experimentalmente (\\(pIC_{50}\\)) se presentan mas adelante. Descriptores moleculares Generación de descriptores Para calcular los descriptores electrónicos, los autores emplearon el paquete Gaussian03. Las geometrías de los 36 derivados de tiadiazol se optimizaron mediante el método DFT (Teoría del Funcional de Densidad), una técnica teórica en química computacional utilizada para calcular propiedades electrónicas de las moléculas. Estos cálculos se realizaron utilizando el conjunto funcional B3LYP, que define las interacciones electrónicas en las moléculas, y la base 6-31G (d), un conjunto de funciones de base utilizado para aproximar las funciones de onda electrónica en los cálculos de DFT. Estos cálculos proporcionaron varios descriptores estructurales clave, incluyendo la energía orbital molecular ocupada más alta (HOMO), la energía orbital molecular desocupada más baja (LUMO), el momento dipolar (μ), la brecha de energía (ΔE) y la energía total. Por otro lado, para calcular una serie de descriptores moleculares adicionales, como el volumen molar MV (cm³), el peso molecular MW (g/mol), la refractividad molar MR (cm³), el parachor Pc (cm³), la densidad D (g/cm³), el índice de refracción n y el coeficiente de partición octanol/agua (logP), se utilizó el programa ChemSketch. Los valores de los 12 descriptores químicos calculados se presentan en la siguiente tabla junto con sus respectivas actividades biológicas calculadas experimentalmente (\\(pIC_{50}\\)). # Cargar datos con los valores de los parametros (descriptores) Valores_Parametros_Tiadiazoles &lt;- read_xlsx(&quot;Valores_Parametros_Tiadiazoles.xlsx&quot;) Valores_Parametros_Tiadiazoles ## # A tibble: 36 × 14 ## N pIC50 MW MR MV Pc nn D Et Ehomo Elumo ΔE ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 4.93 385. 97.7 266. 36.6 1.66 1.45 -44405. -6.59 -2.84 3.75 ## 2 2 4.97 420. 103. 278. 34.4 1.66 1.51 -56919. -6.7 -2.85 3.85 ## 3 3 4.88 420. 103. 278. 34.4 1.66 1.51 -56919. -6.41 -2.92 3.49 ## 4 4 4.58 420. 103. 278. 34.4 1.66 1.51 -56920. -6.69 -2.88 3.82 ## 5 5 4.72 391. 96.0 255. 42.8 1.68 1.53 -53139. -6.38 -3.08 3.3 ## 6 6 4.92 426. 101. 267 40.1 1.68 1.59 -65654. -6.7 -2.88 3.82 ## 7 7 4.88 470. 104. 271. 46.0 1.69 1.73 -123150. -6.65 -2.87 3.78 ## 8 8 4.60 401. 104. 272. 36.7 1.69 1.47 -53199. -6.37 -2.48 3.89 ## 9 9 4.46 436. 109. 284. 34.5 1.69 1.53 -65714. -6.69 -2.93 3.76 ## 10 10 4.22 436. 109. 284. 34.5 1.69 1.53 -65714. -6.7 -2.96 3.74 ## # ℹ 26 more rows ## # ℹ 2 more variables: µµ &lt;dbl&gt;, logP &lt;dbl&gt; La columna “N” en los datos originales es un identificador. Por ahora no la necesitamos. # Crear un nuevo conjunto de datos sin la columna &quot;N&quot; Valores_Parametros_Tiadiazoles_SID &lt;- Valores_Parametros_Tiadiazoles %&gt;% select(-N) # Crear un tibble con los datos data &lt;- Valores_Parametros_Tiadiazoles_SID %&gt;% as_tibble() # Análisis de las variables glimpse(data) ## Rows: 36 ## Columns: 13 ## $ pIC50 &lt;dbl&gt; 4.932, 4.969, 4.880, 4.581, 4.717, 4.921, 4.882, 4.602, 4.463, 4… ## $ MW &lt;dbl&gt; 385.40, 419.84, 419.84, 419.84, 391.42, 425.87, 470.32, 401.46, … ## $ MR &lt;dbl&gt; 97.67, 102.56, 102.56, 102.56, 96.05, 100.95, 103.74, 103.75, 10… ## $ MV &lt;dbl&gt; 265.6, 277.5, 277.5, 277.5, 255.1, 267.0, 271.2, 272.3, 284.2, 2… ## $ Pc &lt;dbl&gt; 36.597, 34.399, 34.399, 34.399, 42.830, 40.057, 46.026, 36.730, … ## $ nn &lt;dbl&gt; 1.66, 1.66, 1.66, 1.66, 1.68, 1.68, 1.69, 1.69, 1.69, 1.69, 1.69… ## $ D &lt;dbl&gt; 1.45, 1.51, 1.51, 1.51, 1.53, 1.59, 1.73, 1.47, 1.53, 1.53, 1.53… ## $ Et &lt;dbl&gt; -44404.76, -56919.44, -56919.28, -56919.54, -53138.85, -65653.52… ## $ Ehomo &lt;dbl&gt; -6.59, -6.70, -6.41, -6.69, -6.38, -6.70, -6.65, -6.37, -6.69, -… ## $ Elumo &lt;dbl&gt; -2.84, -2.85, -2.92, -2.88, -3.08, -2.88, -2.87, -2.48, -2.93, -… ## $ ΔE &lt;dbl&gt; 3.75, 3.85, 3.49, 3.82, 3.30, 3.82, 3.78, 3.89, 3.76, 3.74, 3.73… ## $ µµ &lt;dbl&gt; 3.04, 3.77, 5.40, 2.20, 7.55, 5.74, 6.74, 3.56, 6.05, 5.57, 4.39… ## $ logP &lt;dbl&gt; 1.844, 2.402, 2.402, 2.402, 1.825, 2.199, 2.534, 3.210, 3.768, 3… Construccion del modelo División de datos para nuestro caso práctico Los investigadores dividieron el conjunto de datos aleatoriamente en dos grupos: un conjunto de entrenamiento, que consta de treinta moléculas, se utilizó para construir el modelo cuantitativo. Las moléculas restantes (2, 3, 10, 11, 17 y 18) se reservaron para evaluar el rendimiento del modelo propuesto en un conjunto de prueba. En nuestro caso, la división de los datos también se realizará de forma aleatoria, como se muestra a continuación: # Establecer método de selección de datos de forma aleatoria # set.seed permite que el análisis sea reproducible cuando se utilizan # números aleatorios set.seed(123) # Establecer 80% de los datos en el conjunto de entrenamiento data_split &lt;- initial_split(data, prop = 0.80) # Mostrar objeto con información sobre la partición data_split ## &lt;Training/Testing/Total&gt; ## &lt;28/8/36&gt; # Para obtener los conjuntos de datos resultantes data_train &lt;- training(data_split) data_test &lt;- testing(data_split) # Mostrar dimensiones (número de filas y columnas) dim(data_train) ## [1] 28 13 dim(data_test) ## [1] 8 13 En el artículo, los investigadores utilizaron los descriptores obtenidos para desarrollar un modelo lineal con el propósito de predecir los efectos de los sustituyentes sobre la actividad antileishmania de 30 derivados de tiadiazol (conjunto de entrenamiento) mediante la selección hacia atrás en el MLR. La mejor combinación lineal obtenida incluye tres descriptores seleccionados: la energía Elumo, la energía Ehomo y el coeficiente de partición octanol/agua logP. Las ecuaciones de los modelos se justifican principalmente por el coeficiente de correlación (R), el error cuadrático medio (MSE), la estadística F de Fisher y el nivel de significancia (valor p). En nuestro caso práctico, optamos por realizar el análisis y desarrollo del modelo con MLR directamente en RStudio, una plataforma ampliamente utilizada para estadísticas y análisis de datos. A continuación, presentaremos el procedimiento. Generación modelo MLR # parsnip_addin() # Crear el de modelo y motor lm_model &lt;- linear_reg() %&gt;% set_engine(&quot;lm&quot;) # Flujo de trabajo lm_wflow &lt;- workflow() %&gt;% add_model(lm_model) %&gt;% add_variables(outcome = pIC50, predictors = c(Ehomo, Elumo, logP)) # Ajustar el modelo al conjunto de entrenamiento lm_fit &lt;- fit(lm_wflow, data_train) lm_fit ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Variables ## Model: linear_reg() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## Outcomes: pIC50 ## Predictors: c(Ehomo, Elumo, logP) ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## ## Call: ## stats::lm(formula = ..y ~ ., data = data) ## ## Coefficients: ## (Intercept) Ehomo Elumo logP ## 2.5963 -0.6061 0.8145 0.1364 Para comparar con este modelo lineal, también podemos ajustar un tipo diferente de modelo. Por ejemplo un modelo bosque aleatorio: rf_model &lt;- rand_forest(trees = 1000) %&gt;% set_engine(&quot;ranger&quot;) %&gt;% set_mode(&quot;regression&quot;) rf_wflow &lt;- workflow() %&gt;% add_variables(outcome = pIC50, predictors = c(Ehomo, Elumo, logP)) %&gt;% add_model(rf_model) rf_fit &lt;- rf_wflow %&gt;% fit(data = data_train) Evaluar el desempeño Enfoque de resustitución Cuando medimos el rendimiento con los mismos datos que utilizamos para el entrenamiento (a diferencia de datos nuevos o datos de prueba), decimos que hemos resustituido los datos. # Definir la función estimate_perf modificada estimate_perf &lt;- function(model, dat) { # Capturar los nombres de los objetos `model` y `dat` cl &lt;- match.call() # Captura la llamada a la función y sus argumentos obj_name &lt;- as.character(cl$model) # Obtiene el nombre del objeto &#39;model&#39; como texto data_name &lt;- as.character(cl$dat) # Obtiene el nombre del objeto &#39;dat&#39; como texto # Calcular métricas: reg_metrics &lt;- metric_set(rmse, rsq) # Error cuadrático medio y coeficiente de determinación model %&gt;% predict(dat) %&gt;% # Realiza predicciones del modelo en el conjunto de datos &#39;dat&#39; bind_cols(dat %&gt;% select(pIC50)) %&gt;% # Combina las predicciones con la columna &#39;pIC50&#39; del conjunto de datos reg_metrics(pIC50, .pred) %&gt;% # Calcula las métricas RMSE y RSQ usando &#39;pIC50&#39; como verdad y &#39;.pred&#39; como estimaciones select(-.estimator) %&gt;% # Elimina la columna &#39;.estimator&#39; generada durante el cálculo de las métricas mutate(object = obj_name, data = data_name) # Agrega las columnas &#39;object&#39; y &#39;data&#39; con los nombres de los objetos } Tanto RMSE como \\(R^{2}\\) se calculan. Las estadísticas de resustitución son: estimate_perf(lm_fit, data_train) ## # A tibble: 2 × 4 ## .metric .estimate object data ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 rmse 0.341 lm_fit data_train ## 2 rsq 0.492 lm_fit data_train estimate_perf(rf_fit, data_train) ## # A tibble: 2 × 4 ## .metric .estimate object data ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 rmse 0.214 rf_fit data_train ## 2 rsq 0.899 rf_fit data_train En base a estos resultados, el bosque aleatorio es mucho más capaz de predecir. Apliquemos el modelo de bosque aleatorio al conjunto de prueba: estimate_perf(rf_fit, data_test) ## # A tibble: 2 × 4 ## .metric .estimate object data ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 rmse 0.306 rf_fit data_test ## 2 rsq 0.00791 rf_fit data_test El modelo parece funcionar mucho mejor en los datos con los que se entrenó que en datos de prueba. La discrepancia en el rendimiento entre el conjunto de entrenamiento y el conjunto de prueba puede deberse a la capacidad del modelo para adaptarse a patrones complejos en los datos de entrenamiento, pero esto no garantiza que funcione igual de bien en datos nuevos o desconocidos. Esto es un ejemplo de un posible problema de sobreajuste (overfitting), donde el modelo se ajusta demasiado a los datos de entrenamiento y no generaliza bien a nuevos datos. Al repredecir los datos del conjunto de entrenamiento, la estimación de rendimiento parece demasiado optimista y no es representativa del rendimiento real del modelo. Esto no es recomendable para la mayoría de los modelos. Tampocoo debemos usar directamente los datos de prueba. Entonces, si no debemos usar directamente los datos de prueba ni repredecir las predicciones en el conjunto de entrenamiento, la solución está en utilizar métodos de remuestreo, como la validación cruzada o los conjuntos de validación. Estos métodos nos permiten obtener una evaluación más precisa y realista del rendimiento de nuestro modelo sin caer en la trampa de la sobreajuste que se produce al repredecir el conjunto de entrenamiento. Método de remuestreo Los métodos de remuestreo son técnicas que simulan cómo se utiliza un conjunto de datos para entrenar y evaluar un modelo. La mayoría de los métodos de remuestreo son iterativos, lo que significa que este proceso se repite varias veces. Para cada iteración de remuestreo, los datos se dividen en dos submuestras: Se entrena el modelo con una parte de los datos. Se evalúa el modelo con la otra parte de los datos. Estas partes son similares a los conjuntos de entrenamiento y prueba. Método de remuestreo Validación cruzada La validación cruzada es una técnica fundamental en el aprendizaje automático que mejora la evaluación de modelos al dividir los datos en varios subconjuntos y realizar ciclos de entrenamiento y evaluación. Esto proporciona una evaluación más sólida del rendimiento del modelo y su capacidad de adaptación a nuevos datos. La elección de un número adecuado de “pliegues” es crucial. Un mayor número de pliegues da como resultado estimaciones con un sesgo pequeño pero con una varianza considerable. En cambio, un menor número de pliegues introduce un sesgo mayor pero con una variación más baja. En este caso, tomamos un valor de 10, ya que la replicación reduce el ruido, pero no el sesgo. set.seed(1001) data_folds &lt;- vfold_cv(data_train, v = 10) data_folds ## # 10-fold cross-validation ## # A tibble: 10 × 2 ## splits id ## &lt;list&gt; &lt;chr&gt; ## 1 &lt;split [25/3]&gt; Fold01 ## 2 &lt;split [25/3]&gt; Fold02 ## 3 &lt;split [25/3]&gt; Fold03 ## 4 &lt;split [25/3]&gt; Fold04 ## 5 &lt;split [25/3]&gt; Fold05 ## 6 &lt;split [25/3]&gt; Fold06 ## 7 &lt;split [25/3]&gt; Fold07 ## 8 &lt;split [25/3]&gt; Fold08 ## 9 &lt;split [26/2]&gt; Fold09 ## 10 &lt;split [26/2]&gt; Fold10 data_folds$splits[[1]] %&gt;% analysis() %&gt;% dim() ## [1] 25 13 Alrededor de 25 muestras están en el conjunto de análisis y 13 están en ese conjunto de evaluación en particular. Guardemos las predicciones para visualizar el ajuste y los residuos del modelo: keep_pred &lt;- control_resamples(save_pred = TRUE, save_workflow = TRUE) set.seed(1003) rf_res &lt;- rf_wflow %&gt;% fit_resamples(resamples = data_folds, control = keep_pred) rf_res ## # Resampling results ## # 10-fold cross-validation ## # A tibble: 10 × 5 ## splits id .metrics .notes .predictions ## &lt;list&gt; &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; ## 1 &lt;split [25/3]&gt; Fold01 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [3 × 4]&gt; ## 2 &lt;split [25/3]&gt; Fold02 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [3 × 4]&gt; ## 3 &lt;split [25/3]&gt; Fold03 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [3 × 4]&gt; ## 4 &lt;split [25/3]&gt; Fold04 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [3 × 4]&gt; ## 5 &lt;split [25/3]&gt; Fold05 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [3 × 4]&gt; ## 6 &lt;split [25/3]&gt; Fold06 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [3 × 4]&gt; ## 7 &lt;split [25/3]&gt; Fold07 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [3 × 4]&gt; ## 8 &lt;split [25/3]&gt; Fold08 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [3 × 4]&gt; ## 9 &lt;split [26/2]&gt; Fold09 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [2 × 4]&gt; ## 10 &lt;split [26/2]&gt; Fold10 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [2 × 4]&gt; collect_metrics(rf_res) ## # A tibble: 2 × 6 ## .metric .estimator mean n std_err .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 rmse standard 0.379 10 0.0557 Preprocessor1_Model1 ## 2 rsq standard 0.525 10 0.134 Preprocessor1_Model1 Las estimaciones de desempeño son mas realistas que las estimaciones de resustitución. Para obtener las predicciones del conjunto de evaluación: assess_res &lt;- collect_predictions(rf_res) assess_res ## # A tibble: 28 × 5 ## id .pred .row pIC50 .config ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Fold01 4.35 8 4.62 Preprocessor1_Model1 ## 2 Fold01 4.54 20 4.48 Preprocessor1_Model1 ## 3 Fold01 4.64 22 4.80 Preprocessor1_Model1 ## 4 Fold02 4.79 12 4.1 Preprocessor1_Model1 ## 5 Fold02 4.64 14 4.59 Preprocessor1_Model1 ## 6 Fold02 4.35 19 4.03 Preprocessor1_Model1 ## 7 Fold03 4.36 1 4.02 Preprocessor1_Model1 ## 8 Fold03 4.46 2 4.98 Preprocessor1_Model1 ## 9 Fold03 3.89 16 3.16 Preprocessor1_Model1 ## 10 Fold04 4.67 7 3.98 Preprocessor1_Model1 ## # ℹ 18 more rows "]]
