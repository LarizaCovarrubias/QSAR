
# Caso Práctico Modelo QSAR: Regresión Lineal Múltiple

Este caso práctico se enfoca en la construcción de un modelo QSAR (Análisis Cuantitativo de Relación Estructura-Actividad) mediante regresión lineal múltiple (MLR). Los datos de partida se obtuvieron del artículo titulado "QSAR Study of (5-Nitroheteroaryl-1,3,4-Thiadiazole-2-yl) Piperazinyl Derivatives to Predict New Similar Compounds as Antileishmanial Agents". En dicho artículo, se llevaron a cabo estudios QSAR que incluyeron análisis de componentes principales (PCA), regresión lineal múltiple (MLR), regresión no lineal (RNLM) y cálculos de redes neuronales artificiales (ANN) en una serie de 36 compuestos derivados de (5-Nitroheteroaryl-1,3,4-Thiadiazole-2-yl) Piperazinyl. El objetivo principal era identificar las características estructurales clave necesarias para diseñar nuevos candidatos potentes de esta clase para la actividad antileishmanial.

En este caso práctico, nos proponemos comparar los resultados obtenidos en nuestro ejercicio con los del mencionado artículo, en especial con en el método de regresión lineal múltiple.

La estructura de este caso práctico se dividirá en las siguientes secciones: recopilación de datos, descripción de descriptores moleculares, construcción del modelo, validación del modelo y comparación de resultados.

En el artículo se realizaron múltiples regresiones lineales utilizando el software XLSTAT versión 2013 para predecir los efectos sobre la actividad antileishmania. Nosotros implementaremos el desarrollo del modelo utilizando Rstudio con tidymodels.

```{r}
# Cargar librerias
library(tidymodels) # Modelado de datos
library(readxl) # Importar datos desde archivos Excel
library(yardstick)

```

```{r setup, include=FALSE}
# Establecer el directorio de trabajo actual
knitr::opts_knit$set(root.dir = "/home/lariza/Documentos/CasoPracticoQSAR")
```

**Datos**

-   Fuente de datos

La información sobre la actividad antileishmanial experimental ($pIC_{50}$ en μM) de 36 derivados de tiadiazol se ha recopilado de un estudio previo. Cabe destacar que los valores de $pIC_{50}$ para las 30 moléculas que componen el conjunto de entrenamiento del modelo oscilan en un rango que va desde 3,155 y 5,046. Los detalles sobre las moléculas y sus respectivas actividades biológicas calculadas experimentalmente ($pIC_{50}$) se presentan mas adelante.

**Descriptores moleculares**

-   Generación de descriptores

Para calcular los descriptores electrónicos, los autores emplearon el paquete Gaussian03. Las geometrías de los 36 derivados de tiadiazol se optimizaron mediante el método DFT (Teoría del Funcional de Densidad), una técnica teórica en química computacional utilizada para calcular propiedades electrónicas de las moléculas. Estos cálculos se realizaron utilizando el conjunto funcional B3LYP, que define las interacciones electrónicas en las moléculas, y la base 6-31G (d), un conjunto de funciones de base utilizado para aproximar las funciones de onda electrónica en los cálculos de DFT. Estos cálculos proporcionaron varios descriptores estructurales clave, incluyendo la energía orbital molecular ocupada más alta (HOMO), la energía orbital molecular desocupada más baja (LUMO), el momento dipolar (μ), la brecha de energía (ΔE) y la energía total.

Por otro lado, para calcular una serie de descriptores moleculares adicionales, como el volumen molar MV (cm³), el peso molecular MW (g/mol), la refractividad molar MR (cm³), el parachor Pc (cm³), la densidad D (g/cm³), el índice de refracción n y el coeficiente de partición octanol/agua (logP), se utilizó el programa ChemSketch. Los valores de los 12 descriptores químicos calculados se presentan en la siguiente tabla junto con sus respectivas actividades biológicas calculadas experimentalmente ($pIC_{50}$).


```{r}
# Cargar datos con los valores de los parametros (descriptores)
Valores_Parametros_Tiadiazoles <- read_xlsx("Valores_Parametros_Tiadiazoles.xlsx")

Valores_Parametros_Tiadiazoles
```

La columna "N" en los datos originales es un identificador. Por ahora no la necesitamos.

```{r}
# Crear un nuevo conjunto de datos sin la columna "N"
Valores_Parametros_Tiadiazoles_SID <- Valores_Parametros_Tiadiazoles %>%
  select(-N)

# Tibble con los datos
data <- Valores_Parametros_Tiadiazoles_SID %>%
  as_tibble()

# Análisis de las variables
glimpse(data)
```

**Construccion del modelo**

- División de datos para nuestro caso práctico

Los investigadores dividieron el conjunto de datos aleatoriamente en dos grupos: un conjunto de entrenamiento, que consta de treinta moléculas, se utilizó para construir el modelo cuantitativo. Las moléculas restantes (2, 3, 10, 11, 17 y 18) se reservaron para evaluar el rendimiento del modelo propuesto en un conjunto de prueba. 

En nuestro caso, la división de los datos también se realizará de forma aleatoria, como se muestra a continuación: 


```{r}
# Establecer método de selección de datos de forma aleatoria

# set.seed permite que el análisis sea reproducible cuando se utilizan 
# números aleatorios
set.seed(123)

# Establecer 80% de los datos en el conjunto de entrenamiento
data_split <- initial_split(data, prop = 0.80)
# Mostrar objeto con información sobre la partición
data_split

# Para obtener los conjuntos de datos resultantes
data_train <- training(data_split)
data_test  <- testing(data_split)
# Mostrar dimensiones (número de filas y columnas) 
dim(data_train)
dim(data_test)
```

En el artículo, los investigadores utilizaron los descriptores obtenidos para desarrollar un modelo lineal con el propósito de predecir los efectos de los sustituyentes sobre la actividad antileishmania de 30 derivados de tiadiazol (conjunto de entrenamiento) mediante la selección hacia atrás en el MLR. La mejor combinación lineal obtenida incluye tres descriptores seleccionados: la energía Elumo, la energía Ehomo y el coeficiente de partición octanol/agua logP. Las ecuaciones de los modelos se justifican principalmente por el coeficiente de correlación (R), el error cuadrático medio (MSE), la estadística F de Fisher y el nivel de significancia (valor p).

En nuestro caso práctico, optamos por realizar el análisis y desarrollo del modelo directamente en RStudio, una plataforma ampliamente utilizada para estadísticas y análisis de datos.

-   Generación modelo MLR

```{r}
#parsnip_addin()
# Modelo y motor
lm_model <- 
  linear_reg() %>% 
   set_engine("lm") 

# Flujo de trabajo
lm_wflow <- 
  workflow() %>% 
  add_model(lm_model) %>% 
  add_variables(outcome = pIC50, predictors = c(Ehomo, Elumo, logP))

# Ajuste del modelo al conjunto de entrenamiento
lm_fit <- 
  fit(lm_wflow, data_train)
lm_fit

```
-  Para comparar con este modelo lineal, también podemos ajustar un tipo diferente de modelo. Por ejemplo un modelo bosque aleatorio:

```{r}
rf_model <- 
  rand_forest(trees = 1000) %>% 
  set_engine("ranger") %>% 
  set_mode("regression")

rf_wflow <- 
  workflow() %>% 
 add_variables(outcome = pIC50, predictors = c(Ehomo, Elumo, logP)) %>% 
  add_model(rf_model) 

rf_fit <- 
  rf_wflow %>%
  fit(data = data_train)
```


**Evaluar el desempeño**

- Enfoque de resustitución

Cuando medimos el rendimiento con los mismos datos que utilizamos para el entrenamiento (a diferencia de datos nuevos o datos de prueba), decimos que hemos resustituido los datos.

```{r}
# Definir la función estimate_perf modificada
estimate_perf <- function(model, dat) {
  # Capturar los nombres de los objetos `model` y `dat`
  cl <- match.call() # Captura la llamada a la función y sus argumentos
  obj_name <- as.character(cl$model) # Obtiene el nombre del objeto 'model' como texto
  data_name <- as.character(cl$dat) # Obtiene el nombre del objeto 'dat' como texto
  
  # Calcular métricas:
  reg_metrics <- metric_set(rmse, rsq) # Error cuadrático medio y coeficiente de determinación

  
  model %>%
    predict(dat) %>% # Realiza predicciones del modelo en el conjunto de datos 'dat'
    bind_cols(dat %>% select(pIC50)) %>% # Combina las predicciones con la columna 'pIC50' del conjunto de datos
    reg_metrics(pIC50, .pred) %>% # Calcula las métricas RMSE y RSQ usando 'pIC50' como verdad y '.pred' como estimaciones
    select(-.estimator) %>% # Elimina la columna '.estimator' generada durante el cálculo de las métricas
    mutate(object = obj_name, data = data_name) # Agrega las columnas 'object' y 'data' con los nombres de los objetos
}
```

Tanto RMSE como $R^{2}$ se calculan. Las estadísticas de resustitución son: 

```{r}
estimate_perf(lm_fit, data_train)
estimate_perf(rf_fit, data_train)
```

En base a estos resultados, el bosque aleatorio es mucho más capaz de predecir.

Apliquemos el modelo de regresion lineal y bosque aleatorio al conjunto de prueba:

```{r}
estimate_perf(lm_fit, data_test)
estimate_perf(rf_fit, data_test)
```
El modelo de regresión lineal es mas consistente entre el entrenamiento y las pruebas, esto puede deberse a su complejidad limitada. Por otro lado, el modelo de bosque aleatorio parece funcionar mucho mejor en los datos con los que se entrenó que en datos de prueba, su discrepancia en el rendimiento entre el conjunto de entrenamiento y el conjunto de prueba puede deberse a la capacidad del modelo para adaptarse a patrones complejos en los datos de entrenamiento, pero esto no garantiza que funcione igual de bien en datos nuevos o desconocidos. Esto es un ejemplo de un posible problema de sobreajuste (overfitting), donde el modelo se ajusta demasiado a los datos de entrenamiento y no generaliza bien a nuevos datos.

Al repredecir los datos del conjunto de entrenamiento, la estimación de rendimiento parece demasiado optimista y no es representativa del rendimiento real del modelo. Esto no es recomendable para la mayoría de los modelos.

Tampoco debemos usar directamente los datos de prueba. Entonces, si no debemos usar directamente los datos de prueba ni repredecir las predicciones en el conjunto de entrenamiento, la solución está en utilizar métodos de remuestreo, como la validación cruzada o los conjuntos de validación. Estos métodos nos permiten obtener una evaluación más precisa y realista del rendimiento de nuestro modelo sin caer en la trampa de la sobreajuste que se produce al repredecir el conjunto de entrenamiento.

- Método de remuestreo

Los métodos de remuestreo son técnicas que simulan cómo se utiliza un conjunto de datos para entrenar y evaluar un modelo. La mayoría de los métodos de remuestreo son iterativos, lo que significa que este proceso se repite varias veces. Para cada iteración de remuestreo, los datos se dividen en dos submuestras:

1. Se entrena el modelo con una parte de los datos.
2. Se evalúa el modelo con la otra parte de los datos.

Estas partes son similares a los conjuntos de entrenamiento y prueba. Nos permite determinar qué tan bien funciona el modelo sin utilizar el conjunto de prueba.

- Método de remuestreo
  - Validación cruzada

La validación cruzada es una técnica fundamental en el aprendizaje automático que mejora la evaluación de modelos al dividir los datos en varios subconjuntos y realizar ciclos de entrenamiento y evaluación. Esto proporciona una evaluación más sólida del rendimiento del modelo y su capacidad de adaptación a nuevos datos.

La elección de un número adecuado de "pliegues" es crucial. Un mayor número de pliegues da como resultado estimaciones con un sesgo pequeño pero con una varianza considerable. En cambio, un menor número de pliegues introduce un sesgo mayor pero con una variación más baja. En este caso, tomamos un valor de 10, ya que la replicación reduce el ruido, pero no el sesgo.

```{r}
set.seed(1001)
data_folds <- vfold_cv(data_train, v = 10)
data_folds
```
```{r}
data_folds$splits[[1]] %>% analysis() %>% dim()
```

25 muestras están en el conjunto de análisis y 13 están en ese conjunto de evaluación en particular.

Guardemos las predicciones para visualizar el ajuste y los residuos del modelo:

```{r}
keep_pred <- control_resamples(save_pred = TRUE, save_workflow = TRUE)
#De esta manera, tanto lm_res como rf_res contendrán las predicciones y flujos de trabajo para sus respectivos modelos, pero ambos utilizarán el mismo objeto keep_pred.

#Modelo regresion lineal
set.seed(1003)
lm_res <- 
  lm_wflow %>% 
  fit_resamples(resamples = data_folds, control = keep_pred)
lm_res
collect_metrics(lm_res)

#Modelo bosque aleatorio
set.seed(1003)
rf_res <- 
  rf_wflow %>% 
  fit_resamples(resamples = data_folds, control = keep_pred)
rf_res
collect_metrics(rf_res)


```

En este caso, las estimaciones de desempeño son mas realistas que las estimaciones de resustitución.

Para obtener las predicciones del conjunto de evaluación:

```{r}
assess_res_lm <- collect_predictions(lm_res)
assess_res_lm
assess_res_rf <- collect_predictions(rf_res)
assess_res_rf
```

